<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>无名鼠辈</title>
    <link>https://llc687.top/</link>
    <description>Recent content on 无名鼠辈</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 03 Nov 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://llc687.top/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>“MapReduce及Hive&#34;</title>
      <link>https://llc687.top/post/hadoop%E4%B8%8Ehive/</link>
      <pubDate>Sun, 03 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://llc687.top/post/hadoop%E4%B8%8Ehive/</guid>
      
        <description>

&lt;h2 id=&#34;1-计算框架&#34;&gt;1.计算框架&lt;/h2&gt;

&lt;p&gt;Hadoop 是一个计算框架，目前大型数据计算框架常用的大致有五种：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;仅批处理框架：&lt;code&gt;Apache hadoop&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;仅流处理框架：&lt;code&gt;Apache Storm&lt;/code&gt;、&lt;code&gt;Apache Samza&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;混合框架：&lt;code&gt;Apache Spark&lt;/code&gt;、&lt;code&gt;Apache Flink&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这其中名气最大、使用最广的当属 Hadoop 和 Spark。&lt;/p&gt;

&lt;p&gt;虽然两者都被称为大数据框架，但实际层级不同。Hadoop 是一个分布式数据基础设施，包括计算框架 MapReduce、分布式文件系统 HDFS、YARN 等。而Spark 是专门用来对分布式存储的大数据的处理工具，并不会进行数据存储，更像是 MapReduce 的替代。&lt;/p&gt;

&lt;p&gt;在使用场景上，Hadoop 主要用于离线数据计算，Spark更适用于需要精准实时的场景。本文主要介绍 Hadoop，对 Spark 不做讨论。&lt;/p&gt;

&lt;p&gt;本文介绍下 Hadoop 另一重要组件 MapReduce，以及 Hive。&lt;/p&gt;

&lt;h2 id=&#34;2-mapreduce&#34;&gt;2. MapReduce&lt;/h2&gt;

&lt;h3 id=&#34;2-1-mapreduce-是什么&#34;&gt;2.1 MapReduce 是什么&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;一个基于 Java 的并行分布式计算框架&lt;/strong&gt;。前文有提到 HDFS 提供了基于主从结构的分布式文件系统，基于此存储服务支持，MapReduce 可以实现任务的分发、跟踪、执行等工作，并收集结果。&lt;/p&gt;

&lt;h3 id=&#34;2-2-mapreduce-组成&#34;&gt;2.2 MapReduce 组成&lt;/h3&gt;

&lt;p&gt;MapReduce 主要思想讲的通俗一点就是&lt;strong&gt;将一个大的计算拆分成 Map（映射）和 Reduce（化简）。&lt;/strong&gt;
说到这里，其实 JAVA8 在引入 Lambda 后，也有 map 和 reduce 方法。下面是一段 Java 中的用法：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;n&#34;&gt;List&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Integer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nums&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Arrays&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;asList&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;

&lt;span class=&#34;n&#34;&gt;List&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Integer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;doubleNums&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nums&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;stream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;number&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;number&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;collect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Collectors&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;toList&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;());&lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;结果:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;Optional&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Integer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nums&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;stream&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;reduce&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;Integer:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;结果:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;代码很简单，map 负责归类，reduce 负责计算。而 Hadoop 中的 MapReduce 也有异曲同工之处。&lt;/p&gt;

&lt;h4 id=&#34;下面结合官方案例-wordcount-进行分析&#34;&gt;下面结合官方案例 WordCount 进行分析：&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Java&#34; data-lang=&#34;Java&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Java&#34; data-lang=&#34;Java&#34;&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;WordCount&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;c1&#34;&gt;// Mapper泛型类，4个参数分别代表输入键、值，输出键、值类型
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;static&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;TokenizerMapper&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;extends&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Mapper&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Object&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IntWritable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;{&lt;/span&gt;
        &lt;span class=&#34;kd&#34;&gt;private&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;final&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;static&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IntWritable&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;one&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IntWritable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
        &lt;span class=&#34;kd&#34;&gt;private&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Text&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;word&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;

        &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Object&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Text&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Context&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;context&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;throws&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IOException&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;InterruptedException&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;c1&#34;&gt;// 字符解析
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;            &lt;span class=&#34;n&#34;&gt;StringTokenizer&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;itr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;StringTokenizer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;toString&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;());&lt;/span&gt;
            &lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;itr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;hasMoreTokens&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;())&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
                &lt;span class=&#34;c1&#34;&gt;// nextToken()：返回从当前位置到下一个分隔符的字符串
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;                &lt;span class=&#34;n&#34;&gt;word&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;itr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;nextToken&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;());&lt;/span&gt;
                &lt;span class=&#34;n&#34;&gt;context&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;write&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;word&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;one&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
            &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
        &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
    
    &lt;span class=&#34;c1&#34;&gt;// Reducer同样也是四个参数
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;static&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;IntSumReducer&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;extends&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Reducer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;IntWritable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;IntWritable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;kd&#34;&gt;private&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IntWritable&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IntWritable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;
        &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;reduce&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Text&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Iterable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;IntWritable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Context&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;context&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;throws&lt;/span&gt; 
                                                                  &lt;span class=&#34;n&#34;&gt;IOException&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;InterruptedException&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
            &lt;span class=&#34;c1&#34;&gt;// 循环values，并记录“单词”个数
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;            &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;IntWritable&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
                &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;
            &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;context&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;write&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
        &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;在这段代码中，不难看出程序核心是 &lt;strong&gt;map&lt;/strong&gt; 函数和 &lt;strong&gt;reduce&lt;/strong&gt; 函数。是否 MapReduce 就是由这两者组成的？接着往下看。&lt;/p&gt;

&lt;h3 id=&#34;2-3-map-和-reduce&#34;&gt;2.3 Map 和 Reduce&lt;/h3&gt;

&lt;h4 id=&#34;2-3-1-map&#34;&gt;2.3.1 Map&lt;/h4&gt;

&lt;p&gt;在 WordCount 案例中，明显看到 &lt;code&gt;map&lt;/code&gt; 函数的输入主要是一个 &lt;Key, Value&gt; 对，在本例中，Value 是要统计的所有文本中的一行数据。
&amp;gt; Context 在这里暂时性忽略，其是 Mapper 类的内部抽象类，一般计算中不会用到，可以先当做“上下文”理解。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;map 函数计算过程是&lt;/strong&gt;: 将这行文本中的单词提取出来，针对每个单词输出一个 &lt;word, 1&gt; 的 &lt;Key, Value&gt; 对。之后 MapReduce 会对这些 &lt;word, 1&gt; 进行处理，将相同的 word 放在一起，形成 &lt;word , &lt;1,1,1,1,1,1,1…&gt;&amp;gt; 的 &lt;Key, Value 集合 &gt; 数据结构，再将其输入给 reduce 函数。&lt;/p&gt;

&lt;h4 id=&#34;2-3-2-reduce&#34;&gt;2.3.2 Reduce&lt;/h4&gt;

&lt;p&gt;接着就来看看&lt;code&gt;reduce&lt;/code&gt;,这里输入参数 Values 就是上面提到的由很多个 &lt;code&gt;1&lt;/code&gt; 组成的集合，而 Key 就是具体“单词” word。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;它的计算过程是&lt;/strong&gt;: 将集合里的&lt;code&gt;1&lt;/code&gt;求和，再将单词（word）与这个和（sum）组成一个 &lt;Key, Value&gt;，也就是 &lt;word, sum&gt; 输出。每一个输出就是一个单词和它的词频统计总和了。
在实际处理中一个 map 函数可针对一部分数据进行运算，这样就可以将一个大块数据切分成很多块（这正是 HDFS 做的）。MapReduce 计算框架为每个数据块分配一个 map 函数去计算，从而实现大型数据的分布式计算。&lt;/p&gt;

&lt;p&gt;假设有两个数据块的文本数据需要进行词频统计，MapReduce 计算过程如下图所示：
&lt;img src=&#34;http://img.llc687.top/%E4%B8%8B%E8%BD%BD.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;到这都很容易理解，毕竟只是个 &lt;code&gt;HelloWorld&lt;/code&gt; 的例子~，但整个MapReduce过程中最关键的部分其实是在 map 到 reduce 之间。&lt;/p&gt;

&lt;p&gt;还拿上面例子来说：统计相同单词在所有输入数据中出现的次数，一个 Map 只能处理一部分数据，而热点单词就很可能会出现在所有 Map 中了，意味着同一单词必须要合并到一起统计才能得到正确结果。这种数据关联几乎在所有的大数据计算场景都需要处理，如果是例子这种的当然只对 Key 合并就OK了，但类似数据库 join 操作这种较复杂的，就需对两种类型（或更多）的数据依据 Key 关联。&lt;/p&gt;

&lt;p&gt;这个数据关联操作在 MapReduce中的叫做：&lt;code&gt;shuffle&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;2-4-shuffle&#34;&gt;2.4 shuffle&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;shuffer&lt;/code&gt; 从字面意思来看，&lt;strong&gt;洗牌&lt;/strong&gt;。下面是一个完整的MR过程，看一看如何洗牌。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.llc687.top/shuffer.jpg&#34; style=&#34;zoom:90%;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;先看左半边&#34;&gt;先看左半边&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;从 HDFS 中读取数据，输入数据块到一个个的 map，其中 map 完成计算时，计算结果会存储到本地文件系统。而当 map 快要进行完时，就会启动 shuffle 过程。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如图，shuffle 也可分为两种，在Map端的是 &lt;code&gt;Map shuffle&lt;/code&gt;。大致过程为：Map 任务进程会调用一个 Partitioner 接口，对 Map 产生的每个 &lt;Key, Value&gt; 进行 Reduce 分区选择。再通过 HTTP 通信发送给对应的 Reduce 进程。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这里就实现了对 Map 结果的分区、排序、分割，以及将同一分区的输出合并写入磁盘，得到一个&lt;strong&gt;分区有序&lt;/strong&gt;的文件。这样不管 Map 在哪个服务器节点，相同的 Key 一定会被发送给相同 Reduce 进程。Reduce 进程对收到的 &lt;Key, Value&gt; 排序合并，相同 Key 放在一起，组成 &lt;Key, Value 集合 &gt; 传递给 Reduce 执行。&lt;/p&gt;

&lt;h4 id=&#34;再看右半边&#34;&gt;再看右半边&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;Reduce shuffle&lt;/code&gt;，又可分为复制 Map 输出、排序合并两阶段。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Copy：Reduce 任务从各个 Map 任务拖取数据后，通知父 TaskTracker 状态已更新，TaskTracker 通知 JobTracker。Reduce 会定期向JobTracker 获取 Map 的输出位置，一旦拿到位置，Reduce 任务会从此输出对应的 TaskTracker 上复制输出到本地，不会等到所有的Map任务结束。&lt;/li&gt;
&lt;li&gt;Merge Sort：

&lt;ul&gt;
&lt;li&gt;Copy 的数据先放入内存缓冲区，若缓冲区放得下就把数据写入内存，即内存到内存 merge。&lt;/li&gt;
&lt;li&gt;Reduce 向每个 Map 去拖取数据，内存中每个 Map 对应一块数据，当内存缓存区中存储的数据达到一定程度，开启内存中 merge，把内存中数据merge 输出到磁盘文件中，即内存到磁盘 merge。&lt;/li&gt;
&lt;li&gt;当属于该 reduce 的 map 输出全部拷贝完成，会在 reduce 上生成多个文件，执行合并操作，即磁盘到磁盘 merge。此刻 Map 的输出数据已经是有序的，Merge 进行一次合并排序，所谓 Reduce 端的 sort 过程就是这个合并的过程。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;经过上一步&lt;code&gt;Reduce shuffle&lt;/code&gt;后，reduce进行最后的计算，将输出写入HDFS中。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以上便是 shuffle 大致四个步骤，关键是 map 输出的 &lt;Key, Value&gt;  shuffle 到哪个 Reduce 进程，它由 Partitioner 来实现，MapReduce 框架默认的 Partitioner 用 Key 哈希值对 Reduce 任务数量取模，相同 Key 会落在相同的 Reduce 任务 ID 上。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;getPartition&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;K2&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;V2&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;numReduceTasks&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;hashCode&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Integer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;MAX_VALUE&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;numReduceTasks&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt; 
 &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;如果对 &lt;code&gt;Shuffle&lt;/code&gt; 总结一句话: &lt;strong&gt;分布式计算将不同服务器中的数据合并到一起进行后续计算的过程&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;shuffle 是大数据计算过程中神奇的地方，不管是 MapReduce 还是 Spark，只要是大数据批处理计算，一定会有 shuffle 过程，只有&lt;strong&gt;让数据关联起来&lt;/strong&gt;，它的内在关系和价值才会呈现。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;3-hive&#34;&gt;3. Hive&lt;/h2&gt;

&lt;p&gt;上一部分介绍了 MapReduce，接下来简单谈谈 &lt;code&gt;Hive&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;我觉得任何一项技术的出现都是为了解决某类问题，&lt;code&gt;MapReduce&lt;/code&gt; 毫无疑问简化了大数据开发的编程难度。但实际上进行数据计算更常用的手段可能是 SQL，那么有没有办法直接运行&lt;code&gt;SQL&lt;/code&gt;？&lt;/p&gt;

&lt;h3 id=&#34;3-1-hive是什么&#34;&gt;3.1 Hive是什么&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;基于Hadoop的一个&lt;strong&gt;数据仓库&lt;/strong&gt;系统，定义了一种类SQL查询语言：&lt;strong&gt;Hive SQL&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这里有一个名词 &lt;strong&gt;数据仓库&lt;/strong&gt;，数据仓库是指：面向主题（Subject Oriented）、集成（Integrated）、相对稳定（Non-Volatile）、反应历史变化（Time Variant）的数据集合，用于支持管理决策。&lt;/p&gt;

&lt;p&gt;这么说可能有点抽象，分解一下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;主题：数据仓库针对某个&lt;strong&gt;主题&lt;/strong&gt;来进行组织，&lt;strong&gt;指使用数据仓库决策时所关心的重点方面&lt;/strong&gt;。比如用户行为分析就可以当做一个主题。&lt;/li&gt;
&lt;li&gt;集成：数据仓库要将多个数据源数据存到一起，但数据以前的存储方式不同，要经过&lt;strong&gt;抽取、清洗、转换&lt;/strong&gt;。（也就是 &lt;code&gt;ETL&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;稳定：保存的数据是一系列历史快照，不允许修改，只能分析。&lt;/li&gt;
&lt;li&gt;时变：会定期接收到新的数据，反应出最新的数据变化。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;现在再看下定义：&lt;strong&gt;数据仓库是将多个数据源的数据按照一定的主题集成，进行抽取、清洗、转换。且处理整合后的数据不允许随意修改，只能分析，还需定期更新。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-2-为什么是-hive&#34;&gt;3.2 为什么是 Hive&lt;/h3&gt;

&lt;p&gt;了解了 Hive 的基础定义，想一下：一个依赖于 HDFS 的数据仓库在 Hadoop 环境中可以扮演什么角色？&lt;/p&gt;

&lt;p&gt;前面说到，可不可以让 SQL 直接运行在 Hadoop 平台，这里的答案便是 Hive。&lt;strong&gt;它可以将 Hive SQL 转换为 MapReduce 程序运行。&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hive 初期版本默认 Hive on Mapreduce&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;启动 &lt;code&gt;hive&lt;/code&gt; 前通常要先启动 &lt;code&gt;hdfs&lt;/code&gt; 和 &lt;code&gt;yarn&lt;/code&gt;, 同时一般需要配置 MySQL，Hive 依赖于 HDFS 的数据存储，但为了能操作 HDFS 上的数据集，要知道数据切分格式、存储类型、地址等。这些信息通过一张表存储，称为元数据，可以存储到 MySQL 中。&lt;/p&gt;

&lt;p&gt;现在来看下 Hive 的部分命令&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;新建数据库：&lt;code&gt;create database xxx;&lt;/code&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;删除数据库：&lt;code&gt;drop database xxx;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;建表：&lt;code&gt;create table table_name(col_name data_type);&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Hive 的表有两个概念：&lt;strong&gt;内部表和外部表&lt;/strong&gt;。默认内部表，简单来说，内部表数据存储在每个表相应的HDFS目录下。外部表的数据存在别处，要删除这个外部表，该外部表所指向的数据是不会被删除的，只会删除外部表对应的元数据。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;查询：&lt;code&gt;select * from t_table where a&amp;lt;100 and b&amp;gt;1000;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;连接查询： &lt;code&gt;select a.*,b.* from t_a a join t_b b on a.name=b.name;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;看到这里，可能会觉得我在写 SQL, 没错，对于熟悉 SQL 的人来说，Hive 是非常易于上手的。&lt;/p&gt;

&lt;h3 id=&#34;3-3-hive-sql-to-mapreduce&#34;&gt;3.3 HIVE SQL To MapReduce&lt;/h3&gt;

&lt;p&gt;前面说到 HQL 可以‘转换’为 MapReduce, 下面就来看看：一个 HQL 是如何转化为 MapReduce 的&lt;/p&gt;

&lt;p&gt;Hive的基础架构：
&lt;img src=&#34;http://img.llc687.top/1648d5a405564edf.jpg&#34; style=&#34;zoom:80%;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通过 Client 向 Hive 提交 SQL 命令。如果是 DDL，Hive 就会通过执行引擎 Driver 将数据表的信息记录在 Metastore 元数据组件中，这个组件通常用一个关系数据库实现，记录表名、字段名、字段类型、关联 HDFS 文件路径等 Meta 信息（元信息）。&lt;/p&gt;

&lt;p&gt;如果是DQL，Driver 就会将该语句提交给自己的编译器 进行语法分析、解析、优化等一系列操作，最后生成一个 MapReduce 执行计划。再根据执行计划生成一个 MapReduce 的作业，提交给 Hadoop 的 MapReduce 计算框架处理。&lt;/p&gt;

&lt;p&gt;比如输入一条 &lt;code&gt;select xxx from a ;&lt;/code&gt; 其执行顺序为：首先在 metastore 查询&amp;ndash;&amp;gt; sql 解析&amp;ndash;&amp;gt; 查询优化&amp;mdash;&amp;gt; 物理计划&amp;ndash;&amp;gt; 执行 MapReduce。&lt;/p&gt;

&lt;h2 id=&#34;小结&#34;&gt;小结&lt;/h2&gt;

&lt;p&gt;本文大致阐述了什么是 MapReduce 及其组成和基本原理。同时也介绍了Hive。其实在实践中，并不需要常编写 MapReduce 程序，主要的数据处理还是 SQL 分析，因此 Hive 在大数据应用中的拥有很大的作用。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;林子雨.《大数据技术原理与应用》（第二版）&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://time.geekbang.org/column/article/68489&#34;&gt;MapReduce如何让数据完成一次旅行？&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://andr-robot.github.io/Hadoop中Shuffle过程/&#34;&gt;Hadoop的Shuffle过程&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://juejin.im/entry/5b47008bf265da0fa50a03fc&#34;&gt;Hive架构特点&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Hello World</title>
      <link>https://llc687.top/post/begin/</link>
      <pubDate>Fri, 04 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://llc687.top/post/begin/</guid>
      
        <description>

&lt;h3 id=&#34;先给-hugo-https-gohugo-io-赞一个&#34;&gt;先给&lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt;赞一个！&lt;/h3&gt;

&lt;h4 id=&#34;以及本主题-jane-https-github-com-xianmin-hugo-theme-jane&#34;&gt;以及本主题 &lt;a href=&#34;https://github.com/xianmin/hugo-theme-jane&#34;&gt;jane&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;​&lt;/p&gt;

&lt;p&gt;​        之前在校时也自己用Java写过博客系统，当时还直接拿着当毕设了。也用过一些github上开源的系统，不过迫于产出不是很高（数量和质量&amp;hellip;）。更迫于快不能享受阿里云学生机了，那我可用不起了&amp;hellip;于是搜了搜，找到了Hugo。遂开整。&lt;/p&gt;

&lt;p&gt;​        虽然跑起来的确挺简单，但再配置评论、搜索、域名等还是要花点时间。所幸贫穷和单身让我十一做了宅男，经过一番折腾终于是配好了。&lt;/p&gt;

&lt;p&gt;​       主题用的国人&lt;a href=&#34;https://github.com/xianmin/hugo-theme-jane&#34;&gt;jane&lt;/a&gt;,还是很不错的。评论使用的*utteranc.es*，最初用的gitment,总有些鉴权问题。搜索使用的谷歌自定义搜索。这样本地直接用Typora写，完事生成push就OK了，再配合一下坚果云，将源文件目录做个同步，也有了版本管理哈哈，简直perfect。白嫖让人快乐~~&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title></title>
      <link>https://llc687.top/about/</link>
      <pubDate>Sat, 28 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://llc687.top/about/</guid>
      
        <description>&lt;ul&gt;
&lt;li&gt;Java开发，秃头初级码农。&lt;/li&gt;
&lt;li&gt;热爱游戏、健身、旅游、阅读。&lt;/li&gt;
&lt;li&gt;为能混吃等死而努力。&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
  </channel>
</rss>
